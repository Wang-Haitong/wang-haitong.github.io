<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Haitong Wang</title>

    <meta name="author" content="Haitong Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Haitong Wang (王海同)
                </p>
                <p>I'm a PhD student at the University of Toronto, advised by <a href="https://scholar.google.ca/citations?user=1pCgjH0AAAAJ&hl=en">Prof. Goldie Nejat</a>. Previously, I completed my bachelor's degree at Beihang University.
                </p>
                <p>
                  I am interested in robot learning, with a focus on enabling generalizable navigation and manipulation for mobile robots.
                </p>
                <p style="text-align:center">
                  <a href="mailto:haitong.wang@mail.utoronto.ca">Email</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/haitong-wang-a5707a1ab/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=LA6TYrgAAAAJ&hl=en">Scholar</a> 
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/haitong_2.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/haitong_2.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  <span class="highlight">Highlighted</span> are led or co-led by me.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr>
      <td style="padding:8px;width:20%;vertical-align:middle">
        <div class="one">
          <video width=100% muted autoplay loop>
            <source src="images/splatsearch/splatsearch_video.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models</span>
        <br>
        <a href="https://quest2gm.github.io/">Siddarth Narasimhan</a>,
        <a href="https://mattlisondra.com/">Matthew Lisondra</a>,
        <strong>Haitong Wang</strong>, 
        <a href="https://scholar.google.ca/citations?user=1pCgjH0AAAAJ&hl=en">Goldie Nejat</a>
        <br>
        <em>Preprint</em>, 2025
        <p></p>
        <a href="https://splat-search.github.io/">website</a>
        /
        <a href="https://www.arxiv.org/abs/2511.12972">arXiv</a>
        /
        <a href="https://www.youtube.com/watch?si=N8n-OwlhugrxnyZC&v=vgkZqu9gLpA&feature=youtu.be">video</a>
        /
        <a href="https://github.com/Quest2GM/SplatSearch">code</a>
        <p></p>
      </td>
    </tr>
        

    <tr class="highlight">
      <td style="padding:8px;width:20%;vertical-align:middle">
        <div class="one">
          <video width=100% muted autoplay loop>
            <source src="images/xnav/xnav_thumbnail_edited.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots</span>
        <br>
        <strong>Haitong Wang</strong>, 
        <a href="https://aarontan-git.github.io/">Aaron Hao Tan</a>,
        <a href="https://angusfung.github.io/">Angus Fung</a>,
        <a href="https://scholar.google.ca/citations?user=1pCgjH0AAAAJ&hl=en">Goldie Nejat</a>
        <br>
        <em>Robotics and Automation Letters (RA-L)</em>, 2025
        <br>
        <em>International Conference on Robotics and Automation (ICRA)</em>, 2026
        <br>
        <p></p>
        <a href="https://cross-embodiment-nav.github.io/">website</a>
        /
        <a href="https://www.arxiv.org/abs/2507.14731">arXiv</a>
        /
        <a href="https://youtu.be/flDyg1Dbna0?si=XTqMJN2cErWkEc8Z">video</a>
        <p></p>
        <!-- <p>
        Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p> -->
      </td>
    </tr>

    <tr>
      <td style="padding:8px;width:20%;vertical-align:middle">
        <div class="one">
          <video width=100% muted autoplay loop>
            <source src="images/ham_nav/hamnav.mov" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Mobile Robot Navigation Using Hand-Drawn Maps: A Vision Language Model Approach</span>
        <br>
        <a href="https://aarontan-git.github.io/">Aaron Hao Tan</a>,
        <a href="https://angusfung.github.io/">Angus Fung</a>,
        <strong>Haitong Wang</strong>, 
        <a href="https://scholar.google.ca/citations?user=1pCgjH0AAAAJ&hl=en">Goldie Nejat</a>
        <br>
        <em>Robotics and Automation Letters (RA-L)</em>, 2025
        <br>
        <em>International Conference on Robotics and Automation (ICRA)</em>, 2026
        <br>
        <p></p>
        <a href="https://arxiv.org/abs/2502.00114">arXiv</a>
        /
        <a href="https://www.youtube.com/watch?v=2NOgwqPeIm8&ab_channel=AutonomousSystemsandBiomechatronicsLab%28UniversityofToronto%29">video</a>
        <p></p>
        <!-- <p>
        Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p> -->
      </td>
    </tr>

          
    <tr>
      <td style="padding:8px;width:20%;vertical-align:middle">
        <div class="one">
          <video width=100% muted autoplay loop>
            <source src="images/mllm_search/mllm.mov" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">MLLM-Search: A Zero-Shot Approach to Finding People using Multimodel Large Language Models</span>
        <br>
        <a href="https://angusfung.github.io/">Angus Fung</a>,
        <a href="https://aarontan-git.github.io/">Aaron Hao Tan</a>,
        <strong>Haitong Wang</strong>, 
        <a href="https://scholar.google.ca/citations?user=ONlP52AAAAAJ&hl=en">Beno Benhabib</a>,
        <a href="https://scholar.google.ca/citations?user=1pCgjH0AAAAJ&hl=en">Goldie Nejat</a>
        <br>
        <em>Robotics</em>, 2025
        <br>
        <p></p>
        <a href="https://arxiv.org/pdf/2412.00103">arXiv</a>
        /
        <a href="https://www.youtube.com/watch?v=mzP3vcU611Y&ab_channel=AutonomousSystemsandBiomechatronicsLab%28UniversityofToronto%29">video</a>
        <p></p>
        <!-- <p>
        Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p> -->
      </td>
    </tr>

    <tr class="highlight">
      <td style="padding:8px;width:20%;vertical-align:middle">
        <div class="one">
          <video width=100% muted autoplay loop>
            <source src="images/finder/finder_thumb.mov" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Find Everything: A General Vision Language Model Approach to Multi-Object Search</span>
        <br>
        <a href="https://jeongwoongc.github.io/">Daniel Choi*</a>,
        <a href="https://angusfung.github.io/">Angus Fung*</a>,
				<strong>Haitong Wang*</strong>, 
        <a href="https://aarontan-git.github.io/">Aaron Hao Tan*</a>
        <br>
        <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2025
        <br>
        <em>CoRL workshop on Language and Robot Learning</em>, 2024
        <br>
        <p></p>
        <a href="https://find-all-my-things.github.io/">website</a>
        /
        <a href="https://arxiv.org/abs/2410.00388">arXiv</a>
        /
        <a href="https://www.youtube.com/watch?v=o7Q9-uF8Is4&ab_channel=Syncere">video</a>
        <p></p>
        <!-- <p>
				Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p> -->
      </td>
    </tr>

    <tr class="highlight">
      <td style="padding:8px;width:20%;vertical-align:middle">
        <div class="one">
          <video width=100% muted autoplay loop>
            <source src="images/navformer/navformer.mov" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">NavFormer: A Transformer Architecture for Robot Target-Driven Navigation in Unknown and Dynamic Environments</span>
        <br>
				<strong>Haitong Wang</strong>, 
        <a href="https://aarontan-git.github.io/">Aaron Hao Tan</a>,
        <a href="https://scholar.google.ca/citations?user=1pCgjH0AAAAJ&hl=en">Goldie Nejat</a>
        <br>
        <em>Robotics and Automation Letters (RA-L)</em>, 2024
        <br>
        <em>International Conference on Robotics and Automation (ICRA)</em>, 2025
        <br>
        <p></p>
        <a href="https://arxiv.org/abs/2402.06838">arXiv</a>
        /
        <a href="https://www.youtube.com/watch?v=PSVsLM1eGXo&ab_channel=AutonomousSystemsandBiomechatronicsLab%28UniversityofToronto%29">video</a>
        <p></p>
        <!-- <p>
				Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p> -->
      </td>
    </tr>


    <tr>
      <td style="padding:8px;width:20%;vertical-align:middle">
        <div class="one">
          <img src='images/haptic_glove/overall.png' width=100%>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Five-Fingered Passive Force Feedback Glove Using a Variable Ratio Lever Mechanism</span>
        <br>
        <a href="https://scholar.google.com.hk/citations?user=RKh8gwkAAAAJ&hl=en">Yuan Guo</a>,
        <a href="https://scholar.google.com/citations?hl=en&user=0Zq9688AAAAJ&view_op=list_works">Xiuping Yang</a>,
				<strong>Haitong Wang</strong>, 
        <a href="https://scholar.google.de/citations?hl=en&user=8A6s4sgAAAAJ&view_op=list_works">Yuru Zhang</a>,
        <a href="https://scholar.google.co.nz/citations?user=DlX_-qYAAAAJ&hl=en">Weiliang Xu</a>,
        <a href="https://scholar.google.de/citations?user=rtZ22AEAAAAJ&hl=en">Dangxiao Wang</a>
        <br>
        <em>Actuators</em>, 2021
        <br>
        <p></p>
        <a href="https://www.mdpi.com/2076-0825/10/5/96">paper</a>
        <p></p>
        <!-- <p>
				Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p> -->
      </td>
    </tr>

    <tr>
      <td style="padding:8px;width:20%;vertical-align:middle">
        <div class="one">
          <img src='images/haptic_glove/single_finger.png' width=100%>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Achieving High Stiffness Range of Force Feedback Gloves using Variable Stiffness Mechanism</span>
        <br>
        <a href="https://scholar.google.com.hk/citations?user=RKh8gwkAAAAJ&hl=en">Yuan Guo</a>,
        <a href="https://scholar.google.de/citations?user=rtZ22AEAAAAJ&hl=en">Dangxiao Wang</a>,
        <a href="https://scholar.google.com/citations?user=fhVeIXgAAAAJ&hl=en">Ziqi Wang</a>,
        <a href="https://scholar.google.com/citations?hl=en&user=0Zq9688AAAAJ&view_op=list_works">Xiuping Yang</a>,
				<strong>Haitong Wang</strong>, 
        <a href="https://scholar.google.de/citations?hl=en&user=8A6s4sgAAAAJ&view_op=list_works">Yuru Zhang</a>,
        <a href="https://scholar.google.co.nz/citations?user=DlX_-qYAAAAJ&hl=en">Weiliang Xu</a>

        <br>
        <em>IEEE World Haptics Conference (WHC)</em>, 2019
        <br>
        <p></p>
        <a href="https://ieeexplore.ieee.org/abstract/document/8816160">paper</a>
        <p></p>
        <!-- <p>
				Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p> -->
      </td>
    </tr>


          </tbody></table>

          
    <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
      <tr>
        <td>
          <h2>Projects</h2>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
    <tr>
      <td style="padding:8px;padding-left:16px;width:20%;vertical-align:middle">
        <div class="one">
          <video width=100% muted autoplay loop>
            <source src="images/projects/quadruped.MOV" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">8-DOF Quadruped Robot, ABU Robocon 2019</span>
        <br>
        <p>
          We built a 8-DOF quadruped robot from scratch for the Robocon 2019 competition, and won the national second place. 
          Developed with my teammates from the Beihang Robotics Team.
        </p>
      </td>
    </tr>
    <tr>
      <td style="padding:8px;padding-left:16px;width:20%;vertical-align:middle">
        <div class="one">
          <img src='images/projects/glove.jpg' width=100%>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="papertitle">Soft Haptic Glove with Force and Thermal Feedback, 2019</span>
        <br>
        <p>
          Developed the thermal control system for a soft haptic glove with force and thermal feedback, work done with Ziqi Wang, and Prof. Dangxiao Wang.
        </p>
      </td>
    </tr>
            
    <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
      <tr>
        <td>
          <h2>Teaching</h2>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
      <tr>
        <td style="padding:8px;padding-left:16px;width:100%;vertical-align:middle">
          Teaching Assistant for <strong>MIE443 Mechatronics Systems: Design and Integration</strong>, 2024 Winter, 2025 Winter, 2025 Fall
        </td>
      </tr>
              
           </tbody></table>
          
    <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
      <tr>
        <td>
          <h2>Reviewer</h2>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
      <tr>
        <td style="padding:8px;padding-left:16px;width:100%;vertical-align:middle">
          Reviewer for RA-L, IROS, CoRL.
        </td>
      </tr>
              
           </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website Template from <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;margin:0 auto;border:0;border-spacing:0;padding:16px;"><tbody>
            <tr>
              <td style="padding:0px;text-align:center">
                <span style="display:block;font-size:13px;color:#555555;margin-bottom:8px;">Visitor map</span>
                <div>
                  <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=eB82QA8WTHx5CmdEy2xb9yXtWa14XmvVSkSTXYuCe1I&cl=ffffff&w=a"></script>
                </div>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
